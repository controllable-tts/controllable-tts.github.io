<html>
<!-- HEADER -->
<head>
    <script type="text/javascript" src="js/jquery-3.6.0.min.js"></script>

    <title>Demo page of "YOUR SPEAKER CLASSIFIER IS (SECRETLY) A STYLE ENCODER (ICASSP 2023 review)"</title>
    <!-- <link rel="icon" href="resources/img/icon.png"> -->

    <link rel="stylesheet" href="css/main.css">
    <link rel="stylesheet" href="css/text.css">
    <link rel="stylesheet" href="css/media.css">

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,200;0,300;0,400;0,500;1,100&display=swap"
          rel="stylesheet">
</head>

<!-- MAIN BODY -->
<body>
<div class="main">
    <!-- HEADER -->
    <br>
    <h1 class="wrapper">Demo page of "YOUR SPEAKER CLASSIFIER IS (SECRETLY) A STYLE ENCODER (ICASSP 2023 review)</h1>
    <p class="wrapper">Under review as a conference paper at ICASSP 2023, <a href="">pdf</a></p>

    <!-- ABSTRACT -->
    <h2 class="wrapper">Abstract</h2>
    <p class="wrapper">Text-to-Speech (TTS) systems have recently seen great progress in synthesizing high-quality speech. However, the prosody of generated utterances often is not as diverse as prosody of the natural speech. In the case of multi-speaker or voice cloning systems, this problem becomes even worse as information about prosody may be present in the input text and the speaker embedding. In this paper, we study the phenomenon of the presence of emotional information in speaker embeddings produced by a speaker encoder trained on a large dataset for speaker verification. We show that the produced embeddings include devoted components encoding prosodic information. Moreover, we propose a simple technique for finding such components and show that manipulating them may help in designing an emotional TTS system.</p>

    <h2 class="wrapper">Samples</h2>
    <p class="wrapper">Here we provide audio samples used in the MOS test for systems comparison for different emotions.</p>
    <p class="wrapper"> Models included in comparison: 
        <ul class="wrapper">
            <li><i><b>Baseline</b></i> - Non-attentive Tacotron (NAT) with prosody and pitch predictors (without emotion control),</li>
            <li><i><b>EM</b></i> - NAT with embedding manipulation, </li>
            <li><i><b>EM + SEA</b></i> - EM and style embedding averaging, </li>
            <li><i><b>GST</b></i> - Tacotron with global style tokens</li>
        </ul>
    </p>
    

    <div class="wrapper" >
        <p><b>Text 1:</b> In which fox loses a tail and its elder sister finds one.</p>
        <p><b>Text 2:</b> All smile were real and the happier the more sincere. </p>
        
        <div class='main_samples'></div>
    </table>
    </div>       

    <script language="JavaScript" type="text/javascript" src="js/content_tables.js"></script>
    <br><br><br>
    <p class="wrapper" style="text-align: center; font-weight: 300;">October 2022</p>
    <br><br><br>
</div>

</body>
</html>
